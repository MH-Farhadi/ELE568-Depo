{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spkit as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import mne\n",
    "from scipy import signal\n",
    "import os\n",
    "\n",
    "\n",
    "def Load_Raw(path, sfreq=300, plot_raw=False):\n",
    "    data = np.array(pd.read_csv(path, skiprows=2))\n",
    "    data = np.delete(data, [0, 1, -1, -3, -4], axis=1)\n",
    "    \n",
    "    channel_names = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', \n",
    "                     'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'A1', 'A2', 'Fz', 'Cz', 'Pz', 'ECG']\n",
    "    \n",
    "    X = deepcopy(data)\n",
    "    X = deepcopy(X[10000:-10000])\n",
    "    \n",
    "    ch_types = ['eeg'] * 21 + ['ecg']\n",
    "    info = mne.create_info(channel_names, sfreq, ch_types=ch_types)\n",
    "    raw = mne.io.RawArray(X.T, info)\n",
    "    raw.set_montage('standard_1020')\n",
    "    \n",
    "    if plot_raw:\n",
    "        raw.plot(scalings='auto')\n",
    "    \n",
    "    return raw\n",
    "\n",
    "\n",
    "def Detect_Artifacts(raw):\n",
    "    # Detect amplitude-based artifacts\n",
    "    raw_data = raw.get_data(picks='eeg')\n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # 1. Detect high amplitude artifacts (spikes)\n",
    "    peak_threshold = 100  # microvolts\n",
    "    high_amp_mask = np.abs(raw_data) > peak_threshold\n",
    "    high_amp_percentage = np.mean(high_amp_mask) * 100\n",
    "    \n",
    "    # 2. Detect flat signals (disconnected electrodes)\n",
    "    flat_threshold = 0.5  # microvolts\n",
    "    flat_mask = np.abs(np.diff(raw_data, axis=1)) < flat_threshold\n",
    "    flat_percentage = np.mean(flat_mask) * 100\n",
    "    \n",
    "    # 3. Detect muscle artifacts (high frequency content)\n",
    "    emg_power = []\n",
    "    for ch_idx in range(raw_data.shape[0]):\n",
    "        f, psd = signal.welch(raw_data[ch_idx], fs=sfreq, nperseg=int(sfreq*2))\n",
    "        emg_band = np.logical_and(f >= 30, f <= 100)\n",
    "        emg_power.append(np.mean(psd[emg_band]))\n",
    "    \n",
    "    high_emg_mask = np.array(emg_power) > np.median(emg_power) * 3\n",
    "    emg_affected_channels = np.sum(high_emg_mask)\n",
    "    \n",
    "    # 4. Detect line noise (50/60 Hz)\n",
    "    line_noise_power = []\n",
    "    for ch_idx in range(raw_data.shape[0]):\n",
    "        f, psd = signal.welch(raw_data[ch_idx], fs=sfreq, nperseg=int(sfreq*4))\n",
    "        line_noise_mask = np.logical_or(\n",
    "            np.logical_and(f >= 49, f <= 51),  # 50 Hz\n",
    "            np.logical_and(f >= 59, f <= 61)   # 60 Hz\n",
    "        )\n",
    "        line_noise_power.append(np.mean(psd[line_noise_mask]))\n",
    "    \n",
    "    high_line_noise = np.array(line_noise_power) > np.median(line_noise_power) * 2\n",
    "    line_noise_affected_channels = np.sum(high_line_noise)\n",
    "    \n",
    "    # Calculate overall artifact score (0-100, lower is better)\n",
    "    artifact_score = (\n",
    "        high_amp_percentage * 0.4 +\n",
    "        flat_percentage * 0.3 +\n",
    "        (emg_affected_channels / raw_data.shape[0]) * 100 * 0.15 +\n",
    "        (line_noise_affected_channels / raw_data.shape[0]) * 100 * 0.15\n",
    "    )\n",
    "    \n",
    "    artifact_metrics = {\n",
    "        'high_amplitude_percentage': high_amp_percentage,\n",
    "        'flat_signal_percentage': flat_percentage,\n",
    "        'emg_affected_channels': emg_affected_channels,\n",
    "        'line_noise_affected_channels': line_noise_affected_channels,\n",
    "        'artifact_score': artifact_score  # Overall score, lower is better\n",
    "    }\n",
    "    \n",
    "    return artifact_metrics\n",
    "\n",
    "\n",
    "def Calculate_Signal_Quality(raw):\n",
    "    raw_data = raw.get_data(picks='eeg')\n",
    "    sfreq = raw.info['sfreq']\n",
    "    n_channels = raw_data.shape[0]\n",
    "    \n",
    "    # 1. SNR estimation\n",
    "    snr_values = []\n",
    "    for ch_idx in range(n_channels):\n",
    "        # Get PSD\n",
    "        f, psd = signal.welch(raw_data[ch_idx], fs=sfreq, nperseg=int(sfreq*2))\n",
    "        \n",
    "        # Signal bands (of interest in most EEG studies)\n",
    "        signal_mask = np.logical_or(\n",
    "            np.logical_and(f >= 8, f <= 13),   # Alpha\n",
    "            np.logical_and(f >= 13, f <= 30)   # Beta\n",
    "        )\n",
    "        \n",
    "        # Noise bands (high frequency usually not of interest)\n",
    "        noise_mask = f >= 100\n",
    "        \n",
    "        # Calculate SNR\n",
    "        signal_power = np.mean(psd[signal_mask])\n",
    "        noise_power = np.mean(psd[noise_mask])\n",
    "        \n",
    "        if noise_power > 0:\n",
    "            snr = 10 * np.log10(signal_power / noise_power)\n",
    "        else:\n",
    "            snr = float('inf')\n",
    "            \n",
    "        snr_values.append(snr)\n",
    "    \n",
    "    # 2. Spectral quality - alpha peak presence and prominence\n",
    "    alpha_peak_scores = []\n",
    "    for ch_idx in range(n_channels):\n",
    "        f, psd = signal.welch(raw_data[ch_idx], fs=sfreq, nperseg=int(sfreq*4))\n",
    "        \n",
    "        # Find alpha range\n",
    "        alpha_range = np.logical_and(f >= 8, f <= 13)\n",
    "        alpha_freqs = f[alpha_range]\n",
    "        alpha_psd = psd[alpha_range]\n",
    "        \n",
    "        if len(alpha_freqs) > 0:\n",
    "            # Find peak in alpha range\n",
    "            peak_idx = np.argmax(alpha_psd)\n",
    "            peak_freq = alpha_freqs[peak_idx]\n",
    "            peak_power = alpha_psd[peak_idx]\n",
    "            \n",
    "            # Neighboring frequency bands\n",
    "            theta_power = np.mean(psd[np.logical_and(f >= 4, f <= 7)])\n",
    "            beta_power = np.mean(psd[np.logical_and(f >= 14, f <= 30)])\n",
    "            \n",
    "            # Calculate prominence of alpha peak\n",
    "            prominence = peak_power / ((theta_power + beta_power) / 2)\n",
    "            alpha_peak_scores.append(prominence)\n",
    "        else:\n",
    "            alpha_peak_scores.append(0)\n",
    "    \n",
    "    # 3. Calculate amplitude stability\n",
    "    stability_scores = []\n",
    "    for ch_idx in range(n_channels):\n",
    "        # Split signal into 1-second windows and calculate their std\n",
    "        n_seconds = int(raw_data.shape[1] / sfreq)\n",
    "        window_stds = []\n",
    "        \n",
    "        for i in range(n_seconds):\n",
    "            start_idx = int(i * sfreq)\n",
    "            end_idx = int((i + 1) * sfreq)\n",
    "            if end_idx <= raw_data.shape[1]:\n",
    "                window = raw_data[ch_idx, start_idx:end_idx]\n",
    "                window_stds.append(np.std(window))\n",
    "        \n",
    "        # Stability is inverse of the variability of standard deviations\n",
    "        if len(window_stds) > 0:\n",
    "            stability = 1 / (np.std(window_stds) / np.mean(window_stds))\n",
    "            stability_scores.append(stability)\n",
    "        else:\n",
    "            stability_scores.append(0)\n",
    "    \n",
    "    # Calculate overall signal quality score (0-100, higher is better)\n",
    "    avg_snr = np.mean(snr_values)\n",
    "    avg_alpha_peak = np.mean(alpha_peak_scores)\n",
    "    avg_stability = np.mean(stability_scores)\n",
    "    \n",
    "    # Normalize each component to contribute to a 0-100 scale\n",
    "    norm_snr = min(100, max(0, avg_snr * 5))  # SNR of ~20dB gives 100 points\n",
    "    norm_alpha = min(100, max(0, avg_alpha_peak * 25))  # alpha prominence of ~4 gives 100 points\n",
    "    norm_stability = min(100, max(0, avg_stability * 10))  # stability of ~10 gives 100 points\n",
    "    \n",
    "    quality_score = (norm_snr * 0.4 + norm_alpha * 0.4 + norm_stability * 0.2)\n",
    "    \n",
    "    quality_metrics = {\n",
    "        'snr': avg_snr,\n",
    "        'alpha_peak_prominence': avg_alpha_peak,\n",
    "        'signal_stability': avg_stability,\n",
    "        'quality_score': quality_score  # Overall score, higher is better\n",
    "    }\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "\n",
    "def Calculate_Impedance_Estimate(raw):\n",
    "    raw_copy = raw.copy()\n",
    "    raw_copy.load_data()\n",
    "    \n",
    "    raw_noise = raw_copy.copy()\n",
    "    raw_noise.notch_filter([48, 52], picks='eeg')\n",
    "    raw_noise.notch_filter([58, 62], picks='eeg')\n",
    "    \n",
    "    raw_data = raw_copy.get_data(picks='eeg')\n",
    "    noise_data = raw_noise.get_data(picks='eeg')\n",
    "    line_noise = raw_data - noise_data\n",
    "    \n",
    "    impedance_estimate = np.std(line_noise, axis=1)\n",
    "    mean_impedance = np.mean(impedance_estimate)\n",
    "    \n",
    "    return {\n",
    "        'channel_impedance': impedance_estimate,\n",
    "        'mean_impedance': mean_impedance\n",
    "    }\n",
    "\n",
    "\n",
    "def Evaluate_Electrode_Quality(path, electrode_type, saline_conc):\n",
    "    print(f\"\\nEvaluating {electrode_type} with {saline_conc} saline concentration...\")\n",
    "    \n",
    "    raw = Load_Raw(path)\n",
    "    \n",
    "    # Detect artifacts\n",
    "    artifact_metrics = Detect_Artifacts(raw)\n",
    "    \n",
    "    # Calculate signal quality\n",
    "    quality_metrics = Calculate_Signal_Quality(raw)\n",
    "    \n",
    "    # Estimate impedance\n",
    "    impedance_metrics = Calculate_Impedance_Estimate(raw)\n",
    "    \n",
    "    # Combine all metrics\n",
    "    evaluation = {\n",
    "        'electrode_type': electrode_type,\n",
    "        'saline_concentration': saline_conc,\n",
    "        'artifact_metrics': artifact_metrics,\n",
    "        'quality_metrics': quality_metrics,\n",
    "        'impedance_metrics': impedance_metrics,\n",
    "        'combined_score': quality_metrics['quality_score'] * (1 - artifact_metrics['artifact_score']/100)\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"  Artifact score: {artifact_metrics['artifact_score']:.2f} (lower is better)\")\n",
    "    print(f\"  Quality score: {quality_metrics['quality_score']:.2f} (higher is better)\")\n",
    "    print(f\"  Estimated impedance: {impedance_metrics['mean_impedance']:.2f} (lower is better)\")\n",
    "    print(f\"  Combined score: {evaluation['combined_score']:.2f} (higher is better)\")\n",
    "    \n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def Compare_Electrodes(results_list):\n",
    "    comparison_data = []\n",
    "    \n",
    "    for results in results_list:\n",
    "        row = {\n",
    "            'electrode_type': results['electrode_type'],\n",
    "            'saline_concentration': results['saline_concentration'],\n",
    "            'artifact_score': results['artifact_metrics']['artifact_score'],\n",
    "            'quality_score': results['quality_metrics']['quality_score'],\n",
    "            'mean_impedance': results['impedance_metrics']['mean_impedance'],\n",
    "            'combined_score': results['combined_score']\n",
    "        }\n",
    "        comparison_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    df['config'] = df['electrode_type'] + '_' + df['saline_concentration']\n",
    "    \n",
    "    # Create bar plots for each metric\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(12, 16))\n",
    "    \n",
    "    # Artifact score (lower is better)\n",
    "    axes[0].bar(df['config'], -df['artifact_score'])\n",
    "    axes[0].set_title('Artifact Score (Lower is Better)')\n",
    "    axes[0].set_ylabel('Negative Score')\n",
    "    axes[0].set_xlabel('Electrode Configuration')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Quality score (higher is better)\n",
    "    axes[1].bar(df['config'], df['quality_score'])\n",
    "    axes[1].set_title('Signal Quality Score (Higher is Better)')\n",
    "    axes[1].set_ylabel('Score')\n",
    "    axes[1].set_xlabel('Electrode Configuration')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Impedance (lower is better)\n",
    "    axes[2].bar(df['config'], -df['mean_impedance'])\n",
    "    axes[2].set_title('Estimated Impedance (Lower is Better)')\n",
    "    axes[2].set_ylabel('Negative Impedance')\n",
    "    axes[2].set_xlabel('Electrode Configuration')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Combined score (higher is better)\n",
    "    axes[3].bar(df['config'], df['combined_score'])\n",
    "    axes[3].set_title('Combined Score (Higher is Better)')\n",
    "    axes[3].set_ylabel('Score')\n",
    "    axes[3].set_xlabel('Electrode Configuration')\n",
    "    axes[3].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"electrode_comparison.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Find best configuration\n",
    "    best_idx = df['combined_score'].idxmax()\n",
    "    best_config = df.loc[best_idx]\n",
    "    \n",
    "    print(\"\\n====== BEST ELECTRODE CONFIGURATION ======\")\n",
    "    print(f\"Type: {best_config['electrode_type']}\")\n",
    "    print(f\"Saline Concentration: {best_config['saline_concentration']}\")\n",
    "    print(f\"Combined Score: {best_config['combined_score']:.2f}\")\n",
    "    print(\"==========================================\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    electrode_types = ['felt', 'sponge']\n",
    "    saline_concentrations = ['low', 'medium', 'high']\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for electrode_type in electrode_types:\n",
    "        for saline_conc in saline_concentrations:\n",
    "            config = f\"{electrode_type}_{saline_conc}\"\n",
    "            \n",
    "            try:\n",
    "                # Path to your data file - adjust as needed\n",
    "                path = f\"./data/{config}.csv\"\n",
    "                \n",
    "                # Evaluate electrode quality\n",
    "                evaluation = Evaluate_Electrode_Quality(path, electrode_type, saline_conc)\n",
    "                all_results.append(evaluation)\n",
    "                \n",
    "                # Save individual results\n",
    "                output_dir = \"results\"\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                \n",
    "                result_file = os.path.join(output_dir, f\"{config}_evaluation.txt\")\n",
    "                with open(result_file, 'w') as f:\n",
    "                    f.write(f\"Evaluation of {electrode_type} with {saline_conc} saline concentration\\n\")\n",
    "                    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "                    \n",
    "                    f.write(\"ARTIFACT METRICS:\\n\")\n",
    "                    for key, value in evaluation['artifact_metrics'].items():\n",
    "                        f.write(f\"  {key}: {value:.3f}\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nQUALITY METRICS:\\n\")\n",
    "                    for key, value in evaluation['quality_metrics'].items():\n",
    "                        f.write(f\"  {key}: {value:.3f}\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nIMPEDANCE ESTIMATE:\\n\")\n",
    "                    f.write(f\"  Mean impedance: {evaluation['impedance_metrics']['mean_impedance']:.3f}\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nCOMBINED SCORE: {:.3f}\\n\".format(evaluation['combined_score']))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {config}: {str(e)}\")\n",
    "    \n",
    "    # Compare all electrodes\n",
    "    if len(all_results) > 0:\n",
    "        comparison_df = Compare_Electrodes(all_results)\n",
    "        comparison_df.to_csv(\"electrode_comparison_results.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
